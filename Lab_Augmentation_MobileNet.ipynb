{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab-Augmentation MobileNet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "13505w90q7WOMEpxxMVUh6z5ZhlmKDviy",
      "authorship_tag": "ABX9TyPU9qRwzfUrJi28DRa2osDC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/makezazainw/Project/blob/main/Lab_Augmentation_MobileNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mew3lwAMaXDH"
      },
      "source": [
        "### **ติดตั้ง Kaggle เเละ เรียกใช้ไฟล์ json เพื่อติดต่อใช้ dataset ใน kaggle**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5m_qIXOabnO"
      },
      "source": [
        "# Install Kaggle API\n",
        "!pip install -q kaggle\n",
        "!pip install -q kaggle-cli"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_kkUe3valvy"
      },
      "source": [
        "# only for google colab\n",
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = \"thammatattantipitham\" \n",
        "os.environ['KAGGLE_KEY'] = \"3cf826ab97707228fb1602519992740b\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtsvYa8manW1"
      },
      "source": [
        "!kaggle datasets download -d thammatattantipitham/augmentationthaiherb --unzip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ihulub6paq8a"
      },
      "source": [
        "#สร้างไฟล์ folder ขึ้นมาเเละเพิ่มข้อมูลเข้าไปใน folder\n",
        "!mkdir augmentationlabthaiherb\n",
        "!mv  \"train\" \"val\" augmentationlabthaiherb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUU4GFLxa2pv"
      },
      "source": [
        "### **เริ่มต้นการ import library ต่างๆเเละการเรียกใช้ไฟล์**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08sp2eppa_-2"
      },
      "source": [
        "import sys\n",
        "import time\n",
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import keras\n",
        "\n",
        "from skimage.transform import resize\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow.python.keras.utils import np_utils\n",
        "from tensorflow.python.keras.models import Sequential, Model\n",
        "from tensorflow.python.keras.layers import Dense, Dropout, Flatten, Activation, BatchNormalization\n",
        "from tensorflow.python.keras.layers.convolutional import Conv2D, MaxPooling2D, AveragePooling2D\n",
        "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.python.keras.optimizers import RMSprop\n",
        "from tensorflow.python.keras.applications.vgg19 import VGG19\n",
        "from tensorflow.python.keras.applications.mobilenet import MobileNet\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.applications import InceptionV3\n",
        "sys.version"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SM_5RRq_bAAp"
      },
      "source": [
        "from tensorflow.compat.v1.keras.backend import set_session\n",
        "\n",
        "config = tf.compat.v1.ConfigProto()\n",
        "\n",
        "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
        "\n",
        "config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
        "\n",
        "sess = tf.compat.v1.Session(config=config)\n",
        "\n",
        "set_session(sess)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vm7Vog_bEAP"
      },
      "source": [
        "DATASET_PATH  = 'augmentationlabthaiherb/'\n",
        "IMAGE_SIZE    = (224, 224)\n",
        "NUM_CLASSES   = 10\n",
        "BATCH_SIZE    = 32  # try reducing batch size or freeze more layers if your GPU runs out of memory\n",
        "epochs    = 50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNu6CAPDbECl"
      },
      "source": [
        "#ทำ aug มาเเล้ว\n",
        "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDKsFAH_bEE1"
      },
      "source": [
        "#set training data\n",
        "train_generator = train_datagen.flow_from_directory(DATASET_PATH+ r\"train/\",\n",
        "                                                    target_size = IMAGE_SIZE,\n",
        "                                                    batch_size = BATCH_SIZE,\n",
        "                                                    class_mode='categorical',\n",
        "                                                    shuffle = True,\n",
        "                                                    subset='training')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1nB7VakbG_d"
      },
      "source": [
        "valid_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "valid_generator = valid_datagen.flow_from_directory(DATASET_PATH+ r\"val/\",                                      \n",
        "                                                    target_size = IMAGE_SIZE,\n",
        "                                                    batch_size = 1,\n",
        "                                                    class_mode='categorical',\n",
        "                                                    shuffle = True\n",
        "                                                    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5H1qvuqFbNM6"
      },
      "source": [
        "### **Model MobileNet**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9TaFF44bHBy"
      },
      "source": [
        "# Include the epoch in the file name (uses `str.format`)\n",
        "checkpoint_path = \"training_MobNet/cp-{epoch:04d}.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# Create a callback that saves the model's weights every 5 epochs\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_path, \n",
        "    verbose=1, \n",
        "    save_weights_only=True,\n",
        "    period=50)\n",
        "\n",
        "#Create the model\n",
        "base_MobNet = MobileNet(include_top=False,weights='imagenet',input_shape=(IMAGE_SIZE[0],IMAGE_SIZE[1],3))\n",
        "\n",
        "model_mobnet = Sequential()\n",
        "model_mobnet.add(base_MobNet) \n",
        "model_mobnet.add(Flatten()) \n",
        "model_mobnet.add(Dense(512,activation=('relu'),input_dim=64))\n",
        "model_mobnet.add(Dense(256,activation=('relu'))) \n",
        "model_mobnet.add(Dense(128,activation=('relu'))) \n",
        "#model_mobnet.add(Dropout(.3))\n",
        "model_mobnet.add(Dense(64,activation=('relu')))\n",
        "#model_mobnet.add(Dropout(.2))\n",
        "model_mobnet.add(Dense(10,activation=('softmax')))\n",
        "\n",
        "# Save the weights using the `checkpoint_path` format\n",
        "model_mobnet.save_weights(checkpoint_path.format(epoch=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnKEGJjKbHEL"
      },
      "source": [
        "# Model Summary\n",
        "model_mobnet.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oE2Ja7aGjq7t"
      },
      "source": [
        "model_mobnet.compile(optimizer=Adam(lr=0.0001),  #Adam(lr=1e-5)\n",
        "                  loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqpePAyfbHGf"
      },
      "source": [
        "start = time.time()\n",
        "\n",
        "history = model_mobnet.fit_generator(\n",
        "    generator=train_generator, \n",
        "    steps_per_epoch=train_generator.samples//BATCH_SIZE,   # -> 106 # images 3392 = steps * batch_size = 106 * 32 \n",
        "    epochs=epochs, \n",
        "    validation_steps=valid_generator.samples//BATCH_SIZE, # -> 26 # images 832 = steps * batch_size = 26 * 32\n",
        "    validation_data=valid_generator,\n",
        "    callbacks = [cp_callback],\n",
        "    verbose = 1\n",
        ")\n",
        "\n",
        "end = time.time()\n",
        "duration = end - start\n",
        "print ('\\n model_mobnet took %0.2f seconds (%0.1f minutes) to train for %d epochs'%(duration, duration/60, epochs) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIrhE3LMcsBU"
      },
      "source": [
        "###**ขั้นตอนการ Save file Model เเละ Json**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jkhbODRb0RH"
      },
      "source": [
        "#เปลี่ยนชื่อไฟล์ทุกครั้งเวลา SAVE\n",
        "model_mobnet.save('/content/drive/My Drive/Final Project/Dataset-Lab/Original/saved_model/model-mobnet(auglastest).h5') #ดูจำนวนรอบที่เทรนด้วยว่าทั้งหมดกี่รอบจริงๆเเล้ว\n",
        "model_mobnet.save_weights('/content/drive/My Drive/Final Project/Dataset-Lab/Original/saved_model/weightaugmodel-mobnet.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUbahazNckQo"
      },
      "source": [
        "#Import dependencies\n",
        "!mkdir jsonfile\n",
        "import json\n",
        "from keras.models import model_from_json, load_model\n",
        "with open('jsonfile/model_mobnet(aug).json', 'w') as f:\n",
        "    f.write(model_mobnet.to_json())\n",
        "print(\"Saved model success\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctXhsc5pc-5N"
      },
      "source": [
        "###**เเสดงกราฟข้อมูลค่าความเเม่นยำเเละค่าความสูญเสีย Training เเละ Validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8UxPxbZdNzR"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = model_mobnet.history.history['accuracy']\n",
        "val_acc = model_mobnet.history.history['val_accuracy']\n",
        "\n",
        "loss= model_mobnet.history.history['loss']\n",
        "val_loss= model_mobnet.history.history['val_loss']\n",
        "\n",
        "\n",
        "plt.style.use(\"ggplot\")\n",
        "#  \"Accuracy\"\n",
        "plt.figure(figsize=(15, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epochs')\n",
        "#  \"Loss\"\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0m3J0nidxqf"
      },
      "source": [
        "###**จุด Checkpoint**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjjRM_w0eE5D"
      },
      "source": [
        "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "latest"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBO8Q9Q4eE7E"
      },
      "source": [
        "# Load the previously saved weights\n",
        "model_mobnet.load_weights(latest)\n",
        "\n",
        "# Re-evaluate the model\n",
        "loss, acc = model_mobnet.evaluate(valid_generator, verbose=2)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOnDw5WeeNXc"
      },
      "source": [
        "###**Save model อีกเเบบเพื่อนำไปเเปลงเป็น TensorflwLite**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCKmhkZ2eVSt"
      },
      "source": [
        "# Save the entire model as a SavedModel.\n",
        "model_mobnet.save('saved_model/my_model') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiTau3PReVU1"
      },
      "source": [
        "model= tf.keras.models.load_model('saved_model/my_model')\n",
        "tflite_converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = tflite_converter.convert()\n",
        "open(\"tf_lite_model(200epochsmobnet).tflite\", \"wb\").write(tflite_model) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7P6p0lzeq7g"
      },
      "source": [
        "###**ขั้นตอนของ Prediction เเบบบ Confusion Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tA579sRAeVXH"
      },
      "source": [
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "\n",
        "model = tf.keras.models.load_model('ใส่ path ที่ต้องการทำเป็นไฟล์ .h5')\n",
        "filenames = valid_generator.filenames\n",
        "nb_samples = len(valid_generator)\n",
        "y_prob=[]\n",
        "y_act=[]\n",
        "valid_generator.reset()\n",
        "for _ in range(nb_samples):\n",
        "    x_test, y_test = valid_generator.next()\n",
        "    y_prob.append(model.predict(x_test))\n",
        "    y_act.append(y_test)\n",
        "\n",
        "\n",
        "predicted_class = [list(train_generator.class_indices.keys())[i.argmax()] for i in y_prob]\n",
        "actual_class = [list(train_generator.class_indices.keys())[i.argmax()] for i in y_act]\n",
        "\n",
        "out_df = pd.DataFrame(np.vstack([predicted_class,actual_class]).T,columns=['predicted_class', 'actual_class'])\n",
        "confusion_matrix = pd.crosstab(out_df['actual_class'],out_df['predicted_class'], rownames=['Actual'], colnames=['Predicted'])\n",
        "\n",
        "sn.heatmap(confusion_matrix, cmap='Blues', annot= True, fmt='d')\n",
        "plt.show()\n",
        "print('test accuracy : {}'.format((np.diagonal(confusion_matrix).sum()/confusion_matrix.sum().sum()*100)))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}